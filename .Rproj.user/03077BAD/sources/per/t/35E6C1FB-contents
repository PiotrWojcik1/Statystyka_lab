---
title: "Raport 4"
author: "Piotr Wójcik"
date: "27 04 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
```
<font size="3">
<p>W poniższym dokumencie będę prezentował zadania z czwartej listy z przedmiotu <em>Podstawy Statystyki Praktycznej</em> wykładanego na <em>Uniwersytecie Wrocławskim</em> w roku akademickim 2020/2021 w semestrze letnim.</p>

<h2>Zadanie 1</h2>
<p>W poniższym zadaniu przeprowadzimy 200 razy doświadczenie polegające na wygenerowaniu 10-elementowej próby ze standardowego rozkładu normalnego. Następnie, sprawdzimy jak często prawdziwa średnia $\small \mu = 0$ znajduje się w 95% przedziale ufności dla $\small \mu$, przy czym:</p>
<ul>
<li>rozkład próbkowy będziemy przybliżać rozkładem normalnym,</li>
<li>rozkład próbkowy będziemy przybliżać rozkładem Studenta.</li>
</ul>
<h4>Przybliżenie rozkładem normalnym</h4>
<p>Zaczniemy od rozkładu normalnego, to znaczy, wygenerujemy 200 przedziałów postaci:</p>
$$
\small
\big[ \bar{x} - Z_{0.025} \frac{s}{\sqrt{10}}, \ \bar{x} + Z_{0.025} \frac{s}{\sqrt{10}}\big]. 
$$
<p>Gdzie $\small \bar{x}$ to średnia dla próby i $\small s$ to odchylenie standardowe dla próby. Następnie sprawdzimy, ile z tak wygenerowanych 200 przedziałów zawiera $\small \mu = 0$.</p>
```{r norm200_10, echo = TRUE, warning = FALSE, tidy = TRUE}
randomNorm200_10 <- list()
goodN10 <- 0

for(i in 1:200) {
  randomNorm200_10[[i]] <- c(rnorm(10))
  if((0 >= mean(randomNorm200_10[[i]]) - qnorm(0.025, lower.tail = FALSE)/sqrt(10)) & (0 <= mean(randomNorm200_10[[i]]) + qnorm(0.025, lower.tail = FALSE)/sqrt(10))) {
    goodN10 <- goodN10 + 1
  }
}
```
<p>Z $\small 200$ przedziałów, $\small `r goodN10`$ zawierało prawdziwą wartość oczekiwaną $\small \mu = 0$, co daje nam $\small `r goodN10/2`\%$ przedziałów.</p>

<h4>Przybliżenie rozkładem Studenta</h4>
<p>Zajmiemy się teraz rozkładem Studenta, to znaczy, wygenerujemy 200 przedziałów postaci:</p>
$$
\small
\big[ \bar{x} - t^{*}\frac{s}{\sqrt{10}}, \ \bar{x} + t^{*} \frac{s}{\sqrt{10}} \big]. 
$$
<p>Gdzie $\small \bar{x}$ to średnia dla próby, $\small s$ to odchylenie standardowe dla próby, oraz $\small t^{*}$ to taka wartość, że $\small P(T > t^{*}) = 0.025$, gdzie $\small T$ to rozkład studenta o 9 stopniach swobody. Następnie sprawdzimy, ile z tak wygenerowanych 200 przedziałów zawiera $\small \mu = 0$.</p>
```{r stud200_10, echo = TRUE, warning = FALSE, tidy = TRUE}
goodS10 <- 0

for(i in 1:200) {
  if((0 >= mean(randomNorm200_10[[i]]) - qt(0.025, 9, lower.tail = FALSE)/sqrt(10)) & (0 <= mean(randomNorm200_10[[i]]) + qt(0.025, 9, lower.tail = FALSE)/sqrt(10))) {
    goodS10 <- goodS10 + 1
  }
}
```
<p>Z $\small 200$ przedziałów, $\small `r goodS10`$ zawierało prawdziwą wartość oczekiwaną $\small \mu = 0$, co daje nam $\small `r goodS10/2`\%$ przedziałów. Jest to o $\small `r abs(goodS10/2 - goodN10/2)`$ punktów procentowych więcej, niż w przypadku przybliżania rozkładem normalnym, co nie jest zaskakujące skoro przedział jest szerszy dla rozkładu Studenta.</p>


<h3>100-elementowa próba</h3>

<p>Powtórzymy teraz ten sam eksperyment co poprzednio, tyle że zamiast próby 10-elementowej, weźmiemy próbę 100-elementową.</p>
<h4>Przybliżenie rozkładem normalnym</h4>
<p>Zaczniemy od rozkładu normalnego, to znaczy, wygenerujemy 200 przedziałów postaci:</p>
$$
\small
\big[ \bar{x} - Z_{0.025} \frac{s}{\sqrt{100}}, \ \bar{x} + Z_{0.025} \frac{s}{\sqrt{100}} \big]. 
$$
<p>Gdzie $\small \bar{x}$ to średnia dla próby i $\small s$ to odchylenie standardowe dla próby. Następnie sprawdzimy, ile z tak wygenerowanych 200 przedziałów zawiera $\small \mu = 0$.</p>
```{r norm200_100, echo = TRUE, warning = FALSE, tidy = TRUE}
randomNorm200_100 <- list()
goodN100 <- 0

for(i in 1:200) {
  randomNorm200_100[[i]] <- c(rnorm(100))
  if((0 >= mean(randomNorm200_100[[i]]) - qnorm(0.025, lower.tail = FALSE)/sqrt(100)) & (0 <= mean(randomNorm200_100[[i]]) + qnorm(0.025, lower.tail = FALSE)/sqrt(100))) {
    goodN100 <- goodN100 + 1
  }
}
```
<p>Z $\small 200$ przedziałów, $\small `r goodN100`$ zawierało prawdziwą wartość oczekiwaną $\small \mu = 0$, co daje nam $\small `r goodN100/2`\%$ przedziałów.</p>


<h4>Przybliżenie rozkładem Studenta</h4>
<p>Zajmiemy się teraz rozkładem Studenta, to znaczy, wygenerujemy 200 przedziałów postaci:</p>
$$
\small
\big[ \bar{x} - t^{*}\frac{s}{\sqrt{100}}, \ \bar{x} + t^{*} \frac{s}{\sqrt{100}} \big]. 
$$
<p>Gdzie $\small \bar{x}$ to średnia dla próby, $\small s$ to odchylenie standardowe dla próby, oraz $\small t^{*}$ to taka wartość, że $\small P(T > t^{*}) = 0.025$, gdzie $\small T$ to rozkład studenta o 99 stopniach swobody. Następnie sprawdzimy, ile z tak wygenerowanych 200 przedziałów zawiera $\small \mu = 0$.</p>
```{r stud200_100, echo = TRUE, warning = FALSE, tidy = TRUE}
goodS100 <- 0

for(i in 1:200) {
  if((0 >= mean(randomNorm200_100[[i]]) - qt(0.025, 99, lower.tail = FALSE)/sqrt(100)) & (0 <= mean(randomNorm200_100[[i]]) + qt(0.025, 99, lower.tail = FALSE)/sqrt(100))) {
    goodS100 <- goodS100 + 1
  }
}
```
<p>Z $\small 200$ przedziałów, $\small `r goodS100`$ zawierało prawdziwą wartość oczekiwaną $\small \mu = 0$, co daje nam $\small `r goodS100/2`\%$ przedziałów. Jest to o $\small `r abs(goodS100/2 - goodN100/2)`$ punktów procentowych więcej, niż w przypadku przybliżania rozkładem normalnym. Jest to zdecydowanie mniejsza różnica niż dla eksperymentu 10-elementowego, co jest spowodowane faktem, że wraz ze wzrostem stopni swobody, rozkład studenta zbiega do rozkładu normalnego.</p>
<p>Ostatecznie zbieżemy wszystkie te dane w tabelę:</p>

```{r tableData, echo = TRUE, warning = FALSE, echo = TRUE}
rows = c("$N(0,1)$", "$T(99)$")
column10 <- c(paste(toString(goodN10/2),"%", sep = ""), paste(toString(goodS10/2),"%", sep = ""))
columnt100 <- c(paste(toString(goodN100/2),"%", sep = ""), paste(toString(goodS100/2),"%", sep = ""))
table <- data.frame(column10, columnt100)
row.names(table) <- rows
knitr::kable(table, row.names = TRUE, escape = FALSE, format = "pipe", align = "c", col.names = c("10-elementowa próba", "100-elementowa próba"))
```

<h2>Zadanie 2</h2>
```{r gradesVars, echo = TRUE, warning = FALSE, tidy = TRUE}
grades <- read.table("grades.txt")
colnames(grades) <- c("n", "mean", "IQ", "gender", "PHT")
n <- length(grades$n)
IQmean <- mean(grades$IQ)
IQsd <- sd(grades$IQ)
PHTmean <- mean(grades$PHT)
PHTsd <- sd(grades$PHT)
alpha0.1 <- qt(0.1/2, n, lower.tail = FALSE)
alpha0.05 <- qt(0.05/2, n, lower.tail = FALSE)
alpha0.01 <- qt(0.01/2, n, lower.tail = FALSE)
```
<p>W poniższym zadaniu skorzystamy z bazy danych uczniów z pierwszego raportu z zadania 1. Przy czym tym razem całą bazę o rozmiarze $\small n = `r n`$, zinterpretujemy jako próba z pewnej populacji. Poniżej przedstawimy przedziały ufności, dla średniego ilorazu inteligencji oraz średniego wyniku testu psychologicznego <em>Piers-Harris Children's Self-Concept Scale</em>, dla różnych wartości $\small \alpha$. Przypomnijmy, że średni iloraz inteligencji dla naszej próby wynosi $\small x_{IQ} = `r round(IQmean, 2)`$, oraz odchylenie standardowe $\small s_{IQ} = `r round(IQsd, 2)`$. Średni wynik z testu psychologicznego dla naszej próby wynosi $\small x_{PHT} = `r round(PHTmean, 2)`$, oraz odchylenie standardowe $\small s_{PHT} = `r round(PHTsd, 2)`$.</p>
<h4>Przedziały ufności dla średniego ilorazu inteligencji</h4>
<h5>$\alpha = 0.1$:</h5>
$$
[\small \bar{x_{IQ}} - t^{*}\frac{s_{IQ}}{\sqrt{n}}, \ \bar{x_{IQ}} + t^{*} \frac{s_{IQ}}{\sqrt{n}}] \\
[\small `r round(IQmean, 2)` - `r round(alpha0.1, 3)` \frac{`r round(IQsd, 2)`}{\sqrt{`r n`}}, \ `r round(IQmean, 2)` + `r round(alpha0.1, 3)` \frac{`r round(IQsd, 2)`}{\sqrt{`r n`}}] \\
[\small `r round(IQmean - alpha0.1*IQsd/sqrt(n), 3)`, \ `r round(IQmean + alpha0.1*IQsd/sqrt(n), 3)`].
$$
<h5>$\alpha = 0.05$:</h5>
$$
[\small \bar{x_{IQ}} - t^{*}\frac{s_{IQ}}{\sqrt{n}}, \ \bar{x_{IQ}} + t^{*} \frac{s_{IQ}}{\sqrt{n}}] \\
[\small `r round(IQmean, 2)` - `r round(alpha0.05, 3)` \frac{`r round(IQsd, 2)`}{\sqrt{`r n`}}, \ `r round(IQmean, 2)` + `r round(alpha0.05, 3)` \frac{`r round(IQsd, 2)`}{\sqrt{`r n`}}] \\
[\small `r round(IQmean - alpha0.05*IQsd/sqrt(n), 3)`, \ `r round(IQmean + alpha0.05*IQsd/sqrt(n), 3)`].
$$
<h5>$\alpha = 0.01$:</h5>
$$
[\small \bar{x_{IQ}} - t^{*}\frac{s_{IQ}}{\sqrt{n}}, \ \bar{x_{IQ}} + t^{*} \frac{s_{IQ}}{\sqrt{n}}] \\
[\small `r round(IQmean, 2)` - `r round(alpha0.01, 3)` \frac{`r round(IQsd, 2)`}{\sqrt{`r n`}}, \ `r round(IQmean, 2)` + `r round(alpha0.01, 3)` \frac{`r round(IQsd, 2)`}{\sqrt{`r n`}}] \\
[\small `r round(IQmean - alpha0.01*IQsd/sqrt(n), 3)`, \ `r round(IQmean + alpha0.01*IQsd/sqrt(n), 3)`].
$$

<h4>Przedziały ufności dla średniego wyniku testu</h4>
<h5>$\alpha = 0.1$:</h5>
$$
[\small \bar{x_{PHT}} - t^{*}\frac{s_{PHT}}{\sqrt{n}}, \ \bar{x_{PHT}} + t^{*} \frac{s_{PHT}}{\sqrt{n}}] \\
[\small `r round(PHTmean, 2)` - `r round(alpha0.1, 3)` \frac{`r round(PHTsd, 2)`}{\sqrt{`r n`}}, \ `r round(PHTmean, 2)` + `r round(alpha0.1, 3)` \frac{`r round(PHTsd, 2)`}{\sqrt{`r n`}}] \\
[\small `r round(PHTmean - alpha0.1*PHTsd/sqrt(n), 3)`, \ `r round(PHTmean + alpha0.1*PHTsd/sqrt(n), 3)`].
$$
<h5>$\alpha = 0.05$:</h5>
$$
[\small \bar{x_{PHT}} - t^{*}\frac{s_{PHT}}{\sqrt{n}}, \ \bar{x_{PHT}} + t^{*} \frac{s_{PHT}}{\sqrt{n}}] \\
[\small `r round(PHTmean, 2)` - `r round(alpha0.05, 3)` \frac{`r round(PHTsd, 2)`}{\sqrt{`r n`}}, \ `r round(PHTmean, 2)` + `r round(alpha0.05, 3)` \frac{`r round(PHTsd, 2)`}{\sqrt{`r n`}}] \\
[\small `r round(PHTmean - alpha0.05*PHTsd/sqrt(n), 3)`, \ `r round(PHTmean + alpha0.05*PHTsd/sqrt(n), 3)`].
$$
<h5>$\alpha = 0.01$:</h5>
$$
[\small \bar{x_{PHT}} - t^{*}\frac{s_{PHT}}{\sqrt{n}}, \ \bar{x_{PHT}} + t^{*} \frac{s_{PHT}}{\sqrt{n}}] \\
[\small `r round(PHTmean, 2)` - `r round(alpha0.01, 3)` \frac{`r round(PHTsd, 2)`}{\sqrt{`r n`}}, \ `r round(PHTmean, 2)` + `r round(alpha0.01, 3)` \frac{`r round(PHTsd, 2)`}{\sqrt{`r n`}}] \\
[\small `r round(PHTmean - alpha0.01*PHTsd/sqrt(n), 3)`, \ `r round(PHTmean + alpha0.01*PHTsd/sqrt(n), 3)`].
$$

<h4>Zadanie 3</h4>
```{r incomeDB, echo = TRUE, warning = FALSE, tidy = TRUE}
income <- read.table("income.dat")
colnames(income) <- c("n", "age", "education", "gender", "wage", "sector")
```
<p>W poniższym zadaniu pobierzemy 200-elementową próbę losową ze zbioru danych z raportu pierwszego zadania 3. Następnie skonstruujemy na niej 95% przedziały ufności dla poniższych parametrów korzystając z metody <em>Agrestiego-Coulla</em>:</p>
<ul>
<li>frakcja osób z wyższym wykształceniem $\small p_{W}$,</li>
<li>frakcja kobiet $\small p_{K}$,</li>
<li>frakcja osób zatrudnionych w sektorze prywatnym $\small p_{P}$.</li>
</ul>
```{r incomeEstVar, echo = TRUE, warning = FALSE, tidy = TRUE}
n <- length(income$n)
Z <- qnorm(0.05/2, lower.tail = FALSE)
income200Sample <- income[sample(1:n, size = 200),]
income200W <- income200Sample[(income200Sample$education == 5 | income200Sample$education == 6),]
income200K <- income200Sample[income200Sample$gender == 2,]
income200P <- income200Sample[income200Sample$sector == 5,]
pWA <- (length(income200W$n) + Z*Z/2)/(200 + Z*Z)
pKA <- (length(income200K$n) + Z*Z/2)/(200 + Z*Z)
pPA <- (length(income200P$n) + Z*Z/2)/(200 + Z*Z)
SEWA <- sqrt(pWA*(1-pWA)/(200 + Z))
SEKA <- sqrt(pKA*(1-pKA)/(200 + Z))
SEPA <- sqrt(pPA*(1-pPA)/(200 + Z))
```
Metoda <em>Agrestiego-Coulla</em> różni się od klasycznej metody szacowania frakcji małym przesunięciem. Jeżeli $\small X$ ma rozkład Bernoulliego $\small B(n,p)$, to:
$$
\small \tilde{p} = \frac{X + 0.5(Z_{\alpha/2})^2}{n + (Z_{\alpha/2})^2} \hspace{100px} SE_{\tilde{p}} = \sqrt{\frac{\tilde{p}(1 - \tilde{p})}{n + Z_{\alpha/2}}}.
$$
<p>Stąd dostajemy przedział ufności postaci:</p>
$$
\small[\tilde{p} - Z_{\alpha/2} SE_{\tilde{p}},\ \tilde{p} + Z_{\alpha/2} SE_{\tilde{p}}].
$$
<h4>Frakcja osób z wyższym wykształceniem</h4>
<p>Zaczniemy od 95% przedziału ufności dla frakcji osób z wyższym wykształceniem:</p>
$$
\small[\tilde{p_W} - Z_{0.025} SE_{\tilde{p_W}}, \ \tilde{p_W} + Z_{0.025} SE_{\tilde{p_W}}] \\
\small[`r round(pWA, 2)` - `r round(Z, 3)`\cdot `r round(SEWA, 2)`, \ `r round(pWA, 2)` + `r round(Z, 3)`\cdot `r round(SEWA, 2)`] \\
\small[`r round(pWA - Z*SEWA, 3)`, \ `r round(pWA + Z*SEWA, 3)`].
$$
<h4>Frakcja kobiet</h4>
<p>Przejdziemy teraz do 95% przedziału ufności dla frakcji kobiet:</p>
$$ 
\small[\tilde{p_K} - Z_{0.025} SE_{\tilde{p_K}}, \ \tilde{p_K} + Z_{0.025} SE_{\tilde{p_K}}] \\
\small[`r round(pKA, 2)` - `r round(Z, 3)`\cdot `r round(SEKA, 2)`, \ `r round(pKA, 2)` + `r round(Z, 3)`\cdot `r round(SEKA, 2)`] \\
\small[`r round(pKA - Z*SEKA, 3)`, \ `r round(pKA + Z*SEKA, 3)`].
$$
<h4>Frakcja osób zatrudnionych w sektorze prywatnym</h4>
<p>Na końcu zajmiemy się 95% przedziałem ufności dla frakcji osób zatrudnionych w sektorze prywatnym:</p>
$$ 
\small[\tilde{p_P} - Z_{0.025} SE_{\tilde{p_P}}, \ \tilde{p_P} + Z_{0.025} SE_{\tilde{p_P}}] \\
\small[`r round(pPA, 2)` - `r round(Z, 3)`\cdot `r round(SEPA, 2)`, \ `r round(pPA, 2)` + `r round(Z, 3)`\cdot `r round(SEPA, 2)`] \\
\small[`r round(pPA - Z*SEPA, 3)`, \ `r round(pPA + Z*SEPA, 3)`].
$$
<p>Powtórzymy teraz powyższy eksperyment 200 razy, następnie narysujemy histogramy rozkładów powyższych estymatorów, oraz wyznaczymy procent pokrycia przedziałów ufności.</p>
```{r 200expAVar, echo = TRUE, warning = FALSE, tidy = TRUE}
income200Samples <- list()

for(i in 1:200) {
  income200Samples[[i]] <- income[sample(1:n, size = 200),]
}
```
<h4>Eksperyment dla frakcji osób z wyższym wykształceniem</h4>
```{r pWA200, echo = TRUE, warning = FALSE, tidy = TRUE}
pWA <- c()
lengthWA <- c()
p <- length(income[(income$education == 5 | income$education == 6),]$n)/n
goodWA <- 0
for(i in 1:200) {
  pWA <- c(pWA, (length(income200Samples[[i]][(income200Samples[[i]]$education == 5 | income200Samples[[i]]$education == 6),]$n) + Z*Z/2)/(200 + Z*Z))
  SEA <- sqrt(pWA[i]*(1-pWA[i])/(200 + Z))
  lengthWA <- c(lengthWA, 2*Z*SEA)
  if((p >= pWA[i] - Z*SEA) & (p <= pWA[i] + Z*SEA)) {
    goodWA <- goodWA + 1
  }
}
```
<p>Przypomnijmy, że prawdziwa wartość frakcji osób z wyższym wykształceniem wynosi $\small p_W = `r round(p, 3)`$. Zaprezentujemy teraz histogram rozkładu estymatorów tej frakcji:</p>
```{r histpWA, echo = TRUE, warning = FALSE, tidy = TRUE, fig.width = 8.5}
hist(pWA, col = "#bb5df3", main = NULL, xlab = "estymator frakcji osób z wyższym wykształceniem", ylab = "częstość", freq = FALSE, ylim = c(0, 15))
curve(dnorm(x, mean = mean(pWA), sd = sd(pWA)), col= "#41aae5", lwd=2, add = TRUE)
legend("topright", legend = "n = 200", bty = "n")
```
<p>Z 200 przedziałów ufności, `r goodWA` zawierają rzeczywistą wartość $\small p_W$, czyli `r goodWA/2`%, co nie jest zaskakujące, skoro dobraliśmy przedział ufności na poziomie 95%. Średnia szerokość tych przedziałów wynosi $\small `r round(mean(lengthWA), 5)`$.</p>

<h4>Eksperyment dla frakcji kobiet</h4>
```{r pKA200, echo = TRUE, warning = FALSE, tidy = TRUE}
pKA <- c()
lengthKA <- c()
p <- length(income[income$gender == 2,]$n)/n
goodKA <- 0
for(i in 1:200) {
  pKA <- c(pKA, (length(income200Samples[[i]][income200Samples[[i]]$gender == 2,]$n) + Z*Z/2)/(200 + Z*Z))
  SEA <- sqrt(pKA[i]*(1-pKA[i])/(200 + Z))
  lengthKA <- c(lengthKA, 2*Z*SEA)
  if((p >= pKA[i] - Z*SEA) & (p <= pKA[i] + Z*SEA)) {
    goodKA <- goodKA + 1
  }
}
```
<p>Przypomnijmy, że prawdziwa wartość frakcji kobiet wynosi $\small p_K = `r round(p, 3)`$. Zaprezentujemy teraz histogram rozkładu estymatorów tej frakcji:</p>
```{r histpKA, echo = TRUE, warning = FALSE, tidy = TRUE, fig.width = 9}
hist(pKA, col = "#bb5df3", main = NULL, xlab = "estymator frakcji kobiet", ylab = "częstość", freq = FALSE, ylim = c(0,15))
curve(dnorm(x, mean = mean(pKA), sd = sd(pKA)), col= "#41aae5", lwd=2, add = TRUE)
legend("topright", legend = "n = 200", bty = "n")
```
<p>Z 200 przedziałów ufności, `r goodKA` zawierają rzeczywistą wartość $\small p_K$, czyli `r goodKA/2`%, co nie jest zaskakujące, skoro dobraliśmy przedział ufności na poziomie 95%. Średnia szerokość tych przedziałów wynosi $\small `r round(mean(lengthKA), 5)`$.</p>

<h4>Eksperyment dla frakcji osób zatrudnionych w sektorze prywatnym</h4>
```{r pPA200, echo = TRUE, warning = FALSE, tidy = TRUE}
pPA <- c()
lengthPA <- c()
p <- length(income[income$sector == 5,]$n)/n
goodPA <- 0
for(i in 1:200) {
  pPA <- c(pPA, (length(income200Samples[[i]][income200Samples[[i]]$sector == 5,]$n) + Z*Z/2)/(200 + Z*Z))
  SEA <- sqrt(pPA[i]*(1-pPA[i])/(200 + Z))
  lengthPA <- c(lengthPA, 2*Z*SEA)
  if((p >= pPA[i] - Z*SEA) & (p <= pPA[i] + Z*SEA)) {
    goodPA <- goodPA + 1
  }
}
```
<p>Przypomnijmy, że prawdziwa wartość frakcji osób zatrudnionych w sektorze prywatnym wynosi $\small p_P = `r round(p, 3)`$. Zaprezentujemy teraz histogram rozkładu estymatorów tej frakcji:</p>
```{r histpPA, echo = TRUE, warning = FALSE, tidy = TRUE, fig.width = 9}
hist(pPA, col = "#bb5df3", main = NULL, xlab = "estymator frakcji osób zatrudninych w sektorze prywatnym", ylab = "częstość", ylim = c(0, 15), freq = FALSE)
curve(dnorm(x, mean = mean(pPA), sd = sd(pPA)), col= "#41aae5", lwd=2, add = TRUE)
legend("topright", legend = "n = 200", bty = "n")
```
<p>Z 200 przedziałów ufności, `r goodPA` zawierają rzeczywistą wartość $\small p_K$, czyli `r goodPA/2`%, co nie jest zaskakujące, skoro dobraliśmy przedział ufności na poziomie 95%. Średnia szerokość tych przedziałów wynosi $\small `r round(mean(lengthPA), 5)`$.</p>

<h4>Klasyczne przedziały ufności</h4>
<p>Na koniec powrócimy do klasycznych przedziałów ufności w celu porównania otrzymanych wyników z tymi otrzymanymi wcześniej metodą <em>Agrestiego-Coulla</em>. Wcześniej prezentowaliśmy, jak wygląda konstrukcja <em>Agrestiego-Coulla</em>, więc teraz tylko przypomnim jak wygląda klasyczna konstrukcja. Mianowicie, przedział ufności dla frakcji $\small p$, przy ustalonym poziomie ufności $\small \alpha$ wygląda następująco:</p>
$$
\small \Bigg[ \bar{p} - Z_{\alpha/2} \sqrt{\frac{\bar{p}(1-\bar{p})}{n}}, \ \bar{p} + Z_{\alpha/2} \sqrt{\frac{\bar{p}(1-\bar{p})}{n}} \Bigg]. \\
$$
<p>Gdzie $\small \bar{p}$ to frakcja z próby i $\small n$ to rozmiar próby.</p>
<p>Wyznaczymy teraz wartości dla obu konstrukcji w celu porównania ich:</p>
```{r classicVar, echo = TRUE, warning = FALSE, tidy = TRUE}
n <- length(income$n)
Z <- qnorm(0.05/2, lower.tail = FALSE)
income200Samples <- list()
for(i in 1:200) {
  income200Samples[[i]] <- income[sample(1:n, size = 200),]
}
income200Sample <- income[sample(1:n, size = 200),]

income200W <- income200Sample[(income200Sample$education == 5 | income200Sample$education == 6),]
income200K <- income200Sample[income200Sample$gender == 2,]
income200P <- income200Sample[income200Sample$sector == 5,]
pWA <- round((length(income200W$n) + Z*Z/2)/(200 + Z*Z), 3) #
pKA <- round((length(income200K$n) + Z*Z/2)/(200 + Z*Z), 3) #
pPA <- round((length(income200P$n) + Z*Z/2)/(200 + Z*Z), 3) #
pW <- (length(income200W$n))/200 #
pK <- (length(income200K$n))/200 #
pP <- (length(income200P$n))/200 #
pWAs <- c()
pWs <- c()
lengthWAs <- c()
lengthWs <- c()
goodWA <- 0
goodW <- 0
pW_real <- length(income[(income$education == 5 | income$education == 6),]$n)/n

pKAs <- c()
pKs <- c()
lengthKAs <- c()
lengthKs <- c()
goodKA <- 0
goodK <- 0
pK_real <- length(income[income$gender == 2,]$n)/n

pPAs <- c()
pPs <- c()
lengthPAs <- c()
lengthPs <- c()
goodPA <- 0
goodP <- 0
pP_real <- length(income[income$sector == 5,]$n)/n


for(i in 1:200) {
  pWAs <- c(pWAs, (length(income200Samples[[i]][(income200Samples[[i]]$education == 5 | income200Samples[[i]]$education == 6),]$n) + Z*Z/2)/(200 + Z*Z))
  pWs <- c(pWs, (length(income200Samples[[i]][(income200Samples[[i]]$education == 5 | income200Samples[[i]]$education == 6),]$n))/200)
  pKAs <- c(pKAs, (length(income200Samples[[i]][income200Samples[[i]]$gender == 2,]$n) + Z*Z/2)/(200 + Z*Z))
  pKs <- c(pKs, (length(income200Samples[[i]][income200Samples[[i]]$gender == 2,]$n))/200)
  pPAs <- c(pPAs, (length(income200Samples[[i]][income200Samples[[i]]$sector == 5,]$n) + Z*Z/2)/(200 + Z*Z))
  pPs <- c(pPs, (length(income200Samples[[i]][income200Samples[[i]]$sector == 5,]$n))/200)
  SEWA <- sqrt(pWAs[i]*(1-pWAs[i])/(200 + Z))
  SEW <- sqrt(pWs[i]*(1-pWs[i])/200)
  SEKA <- sqrt(pKAs[i]*(1-pKAs[i])/(200 + Z))
  SEK <- sqrt(pKs[i]*(1-pKs[i])/200)
  SEPA <- sqrt(pPAs[i]*(1-pPAs[i])/(200 + Z))
  SEP <- sqrt(pPs[i]*(1-pPs[i])/200)
  lengthWAs <- c(lengthWAs, 2*Z*SEWA)
  lengthWs <- c(lengthWs, 2*Z*SEW)
  lengthKAs <- c(lengthKAs, 2*Z*SEKA)
  lengthKs <- c(lengthKs, 2*Z*SEK)
  lengthPAs <- c(lengthPAs, 2*Z*SEPA)
  lengthPs <- c(lengthPs, 2*Z*SEP)
  if((pW_real >= pWAs[i] - Z*SEWA) & (pW_real <= pWAs[i] + Z*SEWA)) {
    goodWA <- goodWA + 1
  }
  if((pW_real >= pWs[i] - Z*SEW) & (pW_real <= pWs[i] + Z*SEW)) {
    goodW <- goodW + 1
  }
  if((pK_real >= pKAs[i] - Z*SEKA) & (pK_real <= pKAs[i] + Z*SEKA)) {
    goodKA <- goodKA + 1
  }
  if((pK_real >= pKs[i] - Z*SEK) & (pK_real <= pKs[i] + Z*SEK)) {
    goodK <- goodK + 1
  }
  if((pP_real >= pPAs[i] - Z*SEPA) & (pP_real <= pPAs[i] + Z*SEPA)) {
    goodPA <- goodPA + 1
  }
  if((pP_real >= pPs[i] - Z*SEP) & (pP_real <= pPs[i] + Z*SEP)) {
    goodP <- goodP + 1
  }
}

goodWAP <- goodWA/2 #
goodWP <- goodW/2 #
meanLenWA <- round(mean(lengthWAs), 5) #
meanLenW <- round(mean(lengthWs), 5) #
goodKAP <- goodKA/2 #
goodKP <- goodK/2 #
meanLenKA <- round(mean(lengthKAs), 5) #
meanLenK <- round(mean(lengthKs), 5) #
goodPAP <- goodPA/2 #
goodPP <- goodP/2 #
meanLenPA <- round(mean(lengthPAs), 5) #
meanLenP <- round(mean(lengthPs), 5) #
```
<p>Po zebraniu wszystkich danych, zaprezentujemy je wszystkie w poniższej tabeli:</p> 
```{r table, echo = TRUE, warning = FALSE, tidy = TRUE}
rows = c("$p_W$", "$p_K$", "$p_P$", "% obserwacji dla $p_W$", "% obserwacji dla $p_K$", "% obserwacji dla $p_P$", "średnia długość PU dla $p_W$", "średnia długość PU dla $p_K$", "średnia długość PU dla $p_P$")
columnC <- c(pW, pK, pP, paste(toString(goodWP),"%", sep = ""), paste(toString(goodKP),"%", sep = ""), paste(toString(goodPP),"%", sep = ""), meanLenW, meanLenK, meanLenP)
columntA <- c(pWA, pKA, pPA, paste(toString(goodWAP),"%", sep = ""), paste(toString(goodKAP),"%", sep = ""), paste(toString(goodPAP),"%", sep = ""), meanLenWA, meanLenKA, meanLenPA)
table <- data.frame(columnC, columntA)
row.names(table) <- rows
knitr::kable(table, row.names = TRUE, escape = FALSE, format = "pipe", align = "c", col.names = c("Konstrukcja klasyczna", "Konstrukcja <em>Agrestiego-Coulla</em>"))
```
<h4>Histogramy</h4>
<p>Na zakończenie zaprezentujemy histogramy rozkładów wszystkich frakcji dla porównania:</p>
```{r hists, echo = TRUE, warning = FALSE, tidy = TRUE, fig.height = 7, fig.width = 11}
par(mfrow=c(1,2))
hist(pWs, col = "#bb5df3", main = NULL, xlab = "estymator frakcji osób z wyższym wykształceniem(klasyczna)", ylab = "częstość", freq = FALSE, ylim = c(0, 15))
curve(dnorm(x, mean = mean(pWs), sd = sd(pWs)), col= "#41aae5", lwd=2, add = TRUE)
legend("topright", legend = "n = 200", bty = "n")

hist(pWAs, col = "#ec4c3f", main = NULL, xlab = "estymator frakcji osób z wyższym wykształceniem(A-C)", ylab = "częstość", freq = FALSE, ylim = c(0, 15))
curve(dnorm(x, mean = mean(pWAs), sd = sd(pWAs)), col= "#41aae5", lwd=2, add = TRUE)
legend("topright", legend = "n = 200", bty = "n")

hist(pKs, col = "#bb5df3", main = NULL, xlab = "estymator frakcji kobiet(klasyczna)", ylab = "częstość", freq = FALSE, ylim = c(0, 15))
curve(dnorm(x, mean = mean(pKs), sd = sd(pKs)), col= "#41aae5", lwd=2, add = TRUE)
legend("topright", legend = "n = 200", bty = "n")

hist(pKAs, col = "#ec4c3f", main = NULL, xlab = "estymator frakcji kobiet(A-C)", ylab = "częstość", freq = FALSE, ylim = c(0, 15))
curve(dnorm(x, mean = mean(pKAs), sd = sd(pKAs)), col= "#41aae5", lwd=2, add = TRUE)
legend("topright", legend = "n = 200", bty = "n")

hist(pPs, col = "#bb5df3", main = NULL, xlab = "estymator frakcji osób pracujących w sektorze prywatnym(klasyczna)", ylab = "częstość", freq = FALSE, ylim = c(0, 15))
curve(dnorm(x, mean = mean(pPs), sd = sd(pPs)), col= "#41aae5", lwd=2, add = TRUE)
legend("topright", legend = "n = 200", bty = "n")

hist(pPAs, col = "#ec4c3f", main = NULL, xlab = "estymator frakcji osób pracujących w sektorze prywatnym(A-C)", ylab = "częstość", freq = FALSE, ylim = c(0, 15))
curve(dnorm(x, mean = mean(pPAs), sd = sd(pPAs)), col= "#41aae5", lwd=2, add = TRUE)
legend("topright", legend = "n = 200", bty = "n")
```


